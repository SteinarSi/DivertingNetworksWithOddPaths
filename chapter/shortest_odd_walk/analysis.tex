\section{Analysis}

\begin{figure}
    \centering
    \includesvg[width=10cm]{figures/graphs/small2.svg}
    \caption{No odd $S$-$T$-path exist, but we still have many odd $S$-$T$-walks}
    \label{figure:small2}
\end{figure}

Consider Figure ~\ref{figure:small2}. There are no odd paths from $S$ to $T$, yet we have an infinite amount of odd walks by utilizing the cycle $[A,B,C]$ to offset the parity. Our algorithm would first find an odd walk to $A$, then an even walk to $B$, then an odd walk to $C$, then an even walk to $A$, and lastly an odd walk to $T$. However, the algorithm would search $A$ twice, once for each parity, and the resulting walk is not a path. Therefore this algorithm cannot be used to solve \textsc{Shortest Odd Path}.

\subsection{Correctness}
Let \pyth{(priority, even, u)} be the triple at the front of the queue at any point in the execution of our algorithm.
Claim: If \pyth{even} is true and \pyth{even_done[u]} is false, then \pyth{priority} is the cost of the shortest even path from the source to \pyth{u}.

\begin{proof}
By induction. 

The source vertex \pyth{s} has a best possible even cost of \pyth{0}, and initially we have just \pyth{(0, true, s)} in the queue. When that triple is popped the property holds in the base case.

\todo[inline]{
    Burde yoinke beviset herfra: https://web.engr.oregonstate.edu/~glencora/wiki/uploads/dijkstra-proof.pdf

    Eller herfra: https://community.wvu.edu/~krsubramani/courses/fa05/gaoa/qen/dijk.pdf

    Eller fra INF234

    Også si det samme når det er odd, kanskje
}

\end{proof}

\subsection{Complexity}
Let $(G,s,t)$ be an instance of \textsc{Shortest Odd Walk}, let $n := |V|$ and let $m := |E|$.\\
Claim: the algorithm runs in time at most $O(m \cdot \log m)$, or $O(m \cdot \log n)$ if the graph is simple.
\begin{proof}
    Because of our \pyth{odd_done} and \pyth{even_done} arrays, we can guarantee that each vertex is scanned at most twice, once for each parity. For each scan, we loop through each of the neighbours in linear time, and consider putting them in the queue. The total cost of the scans is therefore at most $O(m)$. A vertex may be put into the queue many times before it is scanned, in the worst case once for each of its neighbours. That means that we put vertices in the queue at most $O(m)$ times, for a total cost of $O(m)$, and removing all of them takes a total of $O(m \cdot \log m)$. 
    
    The algorithm runs in time at most $O(m) + O(m \cdot \log m) = O(m \cdot \log m)$, which shows the first part of the claim.
    
    If the graph is simple we may simplify the complexity further: $O(m \cdot \log m) \subseteq (m \cdot \log n^2) = O(m \cdot 2 \cdot \log n) = O(m \cdot \log n)$, which shows the second part of the claim.
\end{proof}

\subsection{Benchmarking}

\subsection{Discussion}
